<!DOCTYPE html>
<html lang='en'>
<head>
  <meta charset='UTF-8'>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <title>Charles Pedro</title>
  <link rel='stylesheet' href='https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css'>
    
  <link rel="stylesheet" href="style.css">    

</head>
<body>
<div class='header section'>
  <div class='container'>
    <h1 id="top">Charles Pedro</h1>
	<h3>Technical Data Analyst</h3>
    <p>This is a portfolio that highlights some work I've done. </p>
  </div>
</div>
<!--   <p></p>   -->
<div class='main section'>
  <div class='container'>

	<h2>Introduction</h2>
	<p>Most of the projects I have worked on are company-related and therefore proprietary, but I can present use cases and examples. I also present data visualization and web projects from graduate coursework a few years ago.</p>

	<p>It's in progress - more to come.</p>
	<h2>Code examples</h2>

	<a href="#sql">SQL</a><br>
	<span class="tab_1"><a href="#sql_rank">Ranking items with a window function</a><br>	
	<span class="tab_1"><a href="#sql_sum">Basic Aggregation</a><br>		
	<a href="#python">Python</a><br>
	<span class="tab_1"><a href="#python_aws_count">Counting objects in AWS S3</a><br>
	<span class="tab_1"><a href="#python_aws_text">Searching for text in S3 objects</a><br>	
	<span class="tab_1"><a href="#python_wb">Pandas and web development project</a><br>
	<a href="#data_viz">Data Visualization</a>	

	<h2 id="sql">SQL</h2>
	
	
	<!-- RANK WINDOW FUNCTION  -->
	
	
	<h3 id="sql_rank">Ranking items with a window function</h3>	
	<p>This is a simple but practical example that can apply to tables of any reasonable size (I haven't tried on a table with a billion rows using Hive). Let's say we have food in a supermarket's inventory. I'm using DBeaver to access the table in AWS Redshift, FYI.</p>

	<p>Some of the food is old. We need to find the most recent foods so we can throw out the rest.</p>
	<ul>
	<li>within each category, sort and find the most recent two foods by date</li>
	<li>if there's a tie on date, keep the one with a higher rating</li>
	<li>if there's a tie on rating, take the lower priced one</li>
	</ul>
	
	<br>
	<p>Here's the inventory table. Note that we have some ties for date within fruits and veggies. How can we keep the ones highlighted in orange and ignore the gray?</p>
	<br>
	<img src="foods_table.PNG" alt="no image found!">
	<br><br>
	<p>The rank function can help us do that. I'll first show the table with the rank column so we can confirm the logic. For example with veggies, we get the most recent date and where there's a tie for second, we get the higher rated vegetable, which is broccoli.</p> 
	<br>
	<img src="rank_one.PNG">	
	<br><br><br>
	<p>Now all we need to do is find where the rank value is 1 or 2. Most people would do a nested query like this:</p> 
	<br><br>
	<img src="sql_nested.PNG">	
	<br><br><br>
	<p>That works but I also like the common table expression (CTE). For longer queries, I find them more manageable. </p>
	<br><br>
	<img src="sql_cteq.PNG">		
	<br><br>
	<p>Indeed, we get the bananas and broccoli as expected. Where those rows tied on date, we got the one with the higher rating.</p>
	<br>
	
	<!-- BASIC AGGREGATION -->
	<h3 id="sql_sum">Basic Aggregation</h3>		
	
	<p>Continuing with the food inventory example from above, I want to find the following:</p>
	<ul>
	<li>change the "meat" and "fish" labels to "protein"</li>
	<li>find the average price of foods within the new categories</li>
	<li>count the number of food items in each category</li>
	</ul>	
	<br>
	<p>I'll first start with a case statement to rename the labels in a column "new_category", putting it side by side with "category" 
	to confirm it's correct:</p>
	<br>
	<img src="sql_sum_case.PNG">
	<br>
	<br>
	<p>That looks good. Now I'll use a CTE again to find the average and count values. 
	I use the round function to get two decimal places.</p>
	<br>
	<img src="sql_sum_final.PNG">
	<br>
	<br>
	<p>Great. I manually confirmed that the average price of fruit is 9.4875, which shows that the average and round functions work. 
	Also we can easily see the counts of each category are correct.</p>
	<br>
	<p></p>
	<p></p>
	<p></p>
	<p></p>
	<!-- <h2>Python - getting data from a data warehouse</h2>	 -->
	
	
	

	<h2 id="python">Python</h2>		
	
	<h3 id="python_aws_count">Counting objects in AWS S3</h3>
	<p>Let's say we have many objects in S3 and need to count how many there are based on the file extension. Here I test a script using this bucket, the contents of which are shown in the AWS Console:</p>
	<br>
	<img src="s3_bucket.PNG">
	<br><br>
	<p>You could also see the contents using an AWS CLI command:</p>
	<p class="code">$ aws s3 ls s3://test/<br>
	<span class="tab_4">PRE empty_folder/<br>
	2020-02-04 20:50:10    5759690 MovieSimilarities1M.jar<br>
	2020-09-29 18:56:28        130 countries.txt<br>
	2019-07-23 17:24:28         55 fruits.csv<br>
	2020-09-29 18:49:35        153 music.csv<br>
	</p>
	<p></p>	
	<br>
	<p>This is all we need to get started. boto3 is the library that allows Python to talk to S3. I also use "re" which is for regular expressions. It helps with 
	doing search/replace and pattern matching text. All we need to do is import libraries, 
	define the bucket name, and then see what objects AWS returns. </p>		
	<br>
	<p class="code">import boto3<br>
	import re<br>
	<br>
	s3 = boto3.resource('s3')<br>
	bucket = s3.Bucket('test')<br>
	<br>
	for file in bucket.objects.all():<br>
	&nbsp;&nbsp;&nbsp;&nbsp;print(file)</p>	
	<br>
	<p>I'm editing in vim from an EMR cluster. I've been using vim for a long time. Run the script:</p>
	<br>
	<p class="code">$ ./count_bucket_items.py<br>
	s3.ObjectSummary(bucket_name='test', key='MovieSimilarities1M.jar')<br>
	s3.ObjectSummary(bucket_name='test', key='countries.txt')<br>
	s3.ObjectSummary(bucket_name='test', key='empty_folder/')<br>
	s3.ObjectSummary(bucket_name='test', key='fruits.csv')<br>
	s3.ObjectSummary(bucket_name='test', key='music.csv')</p>
	<br>
	<p>This is a good start but note that it prints the folder, which we want to ignore. S3 doesn't have the concept of folders - it's just another object, in the same way that cloud platforms like AWS and Azure don't have "files" either. It's all objects. Anyway we only want to consider actual "files".</p>
	<br>
	<p>This script will iterate through the returned list and do the following:</p>
	<ul>
	<li>ignore any value that ends with a slash / (indicates a folder)</li>
	<li>look for anything with a pattern that has a dot, as in "file.ext", and the extention must have alphabetic characters</li>
	<li>split on the dot "." to get the extension</li>
	<li>increase the count if the extension exists in a dictionary, otherwise add it to the dictionary</li>
	<li>add to overall count of objects</li>
	<li>add to total size of all objects</li>
	<li>print a summary of what was returned</li>
	</ul>
	<br>
	<p class="code">for file in bucket.objects.all():<br>
	<span class="tab_1">if not re.search("/$", file.key):     <br>
	<span class="tab_2">if re.match(".*\.[a-z]+$", file.key): <br>
	<span class="tab_3">ext = file.key.split('.')             <br>
	<span class="tab_3">if ext[-1] in ext_dict.keys():        <br>
	<span class="tab_4">ext_dict[ext[-1]] += 1<br>
	<span class="tab_3">else:<br>
	<span class="tab_4">ext_dict[ext[-1]] = 1<br>
	<span class="tab_2">else:<br>
	<span class="tab_3">print("Something didn't match here\n")<br>
	<span class="tab_2">cnt += 1<br>
	<span class="tab_2">size += file.size<br>
	<br>
	print("found", cnt, "objects\n")<br>
	<br>
	print("extensions found:")<br>
	for x in ext_dict.keys():<br>
	<span class="tab_1">print(x)<br>
	<br>
	print("\ncounts by extension:\n")<br>
	<br>
	for i,j in ext_dict.items():                        # print the extension and number of objects<br>
	<span class="tab_1">print(i,j)<br>
	<br>
	print("\ntotal size of bucket:", round(size/1000000), "Mb")<br>
	<br>
	print("\nFinished extension count")
	</p>
	<br>
	<br>
	<p>Now I run it and get the expected output based on the bucket contents. This can work in production with hundreds or thousands of objects.</p>
	<br>
	<p class="code">$ ./count_bucket_items.py<br>
	Start extension count...<br>
	<br>
	found 4 objects<br>
	<br>
	extensions found:<br>
	csv<br>
	txt<br>
	jar<br>
	<br>
	counts by extension:<br>
	<br>
	csv 2<br>
	txt 1<br>
	jar 1<br>
	<br>
	total size of bucket: 6 Mb<br>
	<br>
	Finished extension count</p>
	<br>
	


	<h3 id="python_aws_text">Searching for text in S3 objects</h3>
	<p>I was once asked to search for any objects in S3 that have a particular column name, among thousands of CSV and tab-delimited text files. This is an example of the solution.</p>
	<p>If you recall from the previous example, there was a file called "countries.txt" in the S3 bucket. These are the contents:
	<br>
	<br>
	<img src="s3_countries.PNG">
	<br>
	<br>
	<p>In this example, the ask is to find any object in the bucket that has a column called "continent". Here is the approach:</p>
	<br>
	<ul>
	<li>get a list of all objects in the bucket</li>
	<li>iterate through the list and filter out anything that does not end in .csv or .txt</li>
	<li>put together the request and send to S3; the important part is a kind of SQL statement to get just the first line of an object</li>
	<li>iterate through the objects and save to a list any objects that match the text we want</li>
	<li>print the objects and column names where the text match was found</li>
	<li>I also included a "not_read" list if any files for some reason could not be read</li>
	</ul>
	<br>
	<p class="code">import boto3<br>
	import re<br>
	import botocore.exceptions<br>
	<br>
	s3 = boto3.client('s3')<br>
	bucket = "test"<br>
	obj_list = []<br>
	not_read = []<br>
	text_match = {}<br>
	cnt = 0<br>
	<br>
	<b># get a list of all objects in the bucket</b><br>
	r = s3.list_objects_v2(Bucket=bucket)<br>
	<br>
	print("Starting here:\n")<br>
	<br>
	<b># filter for only objects ending in .csv or .txt, save to obj_list</b><br>
	for x in r['Contents']:<br>
	<span class="tab_1">for key, val in x.items():<br>
	<span class="tab_2">if key == 'Key' and re.search(".*\.(csv|txt)+$", val):<br>
				print(val)<br>
				obj_list.append(val)<br>
				cnt += 1<br>

	print("\ntotal objects: ", cnt)<br>
	<br>
	<b># use a SQL-like statement, doing a "limit 1" because we only need to check the first line</b><br>
	sql_stmt = """select * from s3object limit 1"""<br>
	<br>
	for obj in obj_list:<br>
	<span class="tab_1">try:<br>
	<span class="tab_2">req = s3.select_object_content(<br>
	<span class="tab_2">Bucket=bucket,<br>
	<span class="tab_2">Key=obj,<br>
	<span class="tab_2">ExpressionType='SQL',<br>
	<span class="tab_2">Expression=sql_stmt,<br>
	<span class="tab_2"><b># 'FileHeaderInfo': 'NONE' is needed or else it would ignore the first line</b><br>
	<span class="tab_2">InputSerialization = {'CSV': {'AllowQuotedRecordDelimiter':True, 'FileHeaderInfo': 'NONE'}},<br>
	<span class="tab_2">OutputSerialization = {'CSV': {}})<br>
	<span class="tab_1">except botocore.exceptions.ClientError:<br>
	<span class="tab_2">not_read.append(obj)<br>
	<span class="tab_1">else:<br>
	<span class="tab_2">try:<br>
	<span class="tab_3"><b># Payload has the first line of the file</b><br>
	<span class="tab_3">for event in req['Payload']:<br>
	<span class="tab_4">for key, val in event.items():<br>
	<span class="tab_5">if key == 'Records':<br>
	<span class="tab_6">first_line = val['Payload'].decode('utf-8')<br>
	<span class="tab_6">match = re.findall(r"continent", first_line, re.IGNORECASE)<br>
	<span class="tab_6">if match:<br>
	<span class="tab_7">text_match[obj] = first_line <br>
	<span class="tab_2">except botocore.exceptions.EventStreamError as error:<br>
	<span class="tab_3">csv_unescaped.append(obj)<br>
	<span class="tab_3">raise error<br>
	<br>
	if len(not_read) > 0:<br>
	<span class="tab_1">print("**************** could not read these files!\n")<br>
	<span class="tab_1">for x in not_read:<br>
	<span class="tab_2">print(x)<br>
	<br>
	print("\n************************ found a match in this file!\n")<br>
	for x, y in text_match.items():<br>
	<span class="tab_1">print(x, y)<br>
	<br>
	print("\nScript end")<br>
	</p>
	<br>
	<br>
	<p>With all of that, run the script:</p>
	<p class="code">$ ./s3_text_search.py<br>
	Starting here:<br>
	<br>
	countries.txt<br>
	fruits.csv<br>
	music.csv<br>
	<br>
	total objects:  3<br>
	<br>
	************************ found a match in this file!<br>
	<br>
	countries.txt country   continent<br>
	<br>
	<br>
	Script end</p>
	<br>
	<br>
	<p>As expected, the script prints all .csv and .txt objects, the total count, and any matches, which in this case was the "countries.txt" object</p>
	<br>
	<br>
	<p></p>
	<p></p>
	<p></p>	
	<p></p>
	<p></p>
	<p></p>
	<p></p>	
	
	<h3 id="python_wb">Pandas and web development project</h3>
	<h4>Exploring the World Bank API and development indicators</h4>	
	
	<p>How effective is aid? Much has been written about the economic failures of Latin America in the 1970s and in Africa throughout the 1980s and 90s. Despite massive amounts of aid, many countries failed to achieve economic growth or quality of life improvements.</p>

	<p>This project tries to measure the effectiveness of aid by looking at how much countries have received compared to a few development indicators.</p>	
	
	<p><a href="http://damp-waters-3821.herokuapp.com/">The Effectiveness of Foreign Aid</a></p>      		
	
	<h4>Jupyter Notebook and Pandas Update</h4>
	  
	<p>The above website is still up but the Python code doesn't work because the World Bank changed their API. I just re-wrote the code using Jupyter Notebook and Pandas, which I had not yet known about back in 2015! </p>

	<p><a href="https://github.com/charlespedro/worldbank/blob/master/world_bank.ipynb">Jupyter Notebook dataframe - calculations and aggregation</a></p> 
	
	<br>
	<h2 id="data_viz">Data Visualization</h2>
	<h3>Data Visualization final project</h3>
	<p>These are various visualizations creating using R, High Charts, Google Charts, and Tableau. The topics include health, education, economy, demographics, and other social indicators.</p>

	<p><a href="http://charlespedro.github.io/data-viz-1-final/">Data Visualization Final Project</a></p>      
	
	<h3>Advanced Data Visualization final project</h3>	
	<p>Created with JavaScript and D3, this project explores US imports and exports by comparing the trade of goods and services.</p>	
	<p><a href="http://charlespedro.github.io/data-viz-2-final/">Advanced Data Visualization Final Project</a></p>  	
	
	<br>
	<br>
	<a href="#top">Back to top</a><br>
	<br>
	<br>
  </div>
</div>    
   
    
</body>
</html> 